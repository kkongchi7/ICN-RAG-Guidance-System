# -*- coding: utf-8 -*- 
"""
bus_search_chroma.py
ì¸ì²œê³µí•­ ë²„ìŠ¤ ë…¸ì„  ê²€ìƒ‰ (LLMì„ ì´ìš©í•œ ëª©ì ì§€ ì¶”ì¶œ + ChromaDB ê²€ìƒ‰)
"""

import requests
from bs4 import BeautifulSoup
import chromadb
from sentence_transformers import SentenceTransformer
import time
import csv
import openai
import ast
import pandas as pd

openai_client = openai.OpenAI()

# ===== ì„¤ì • =====
# (ì´ì „ì— ì„±ê³µí–ˆë˜ ì„¤ì •ê°’ê³¼ ì¼ì¹˜ì‹œì¼œì„œ DBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤)
CHROMA_PATH = "./chroma_bus_db" 
COLLECTION_NAME = "bus_routes"
MODEL_NAME = "intfloat/multilingual-e5-base"


# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# NOTE: ì´ë¯¸ ì„ë² ë”© ì‹œì ì— E5 ëª¨ë¸ë¡œ ë²¡í„°ê°€ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ,
# ë‹¨ìˆœíˆ ì»¬ë ‰ì…˜ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
client = chromadb.PersistentClient(path=CHROMA_PATH)
collection = client.get_collection(COLLECTION_NAME) 
model = SentenceTransformer(MODEL_NAME)

# =======================
# ğŸš LLMì„ í†µí•œ ëª©ì ì§€ ì¶”ì¶œ
# =======================
def extract_destination_from_query(query: str) -> str:
    """
    LLMì„ ì´ìš©í•´ ì§ˆì˜ì—ì„œ ëª©ì ì§€ ì¶”ì¶œ
    """
    prompt = f"""
    ì•„ë˜ ì‚¬ìš©ì ì§ˆì˜ì—ì„œ ëª©ì ì§€ë¡œ ì¶”ì¸¡ë˜ëŠ” ì¥ì†Œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. 
    ì£¼ì˜ì‚¬í•­:
    - ì •í™•í•œ ì¥ì†Œë§Œ ì¶”ì¶œí•˜ì„¸ìš”. ì¶”ê°€ì ì¸ ì¶”ì¸¡ì€ ê¸ˆì§€ì…ë‹ˆë‹¤.
    
    ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
    ëª©ì ì§€: 
    """
    
    response = openai_client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=50,
        temperature=0,
        n=1,
        stop=None
    )

    destination = response.choices[0].message.content.strip()
    return destination


# =======================
# ğŸ“ƒ CSV íŒŒì¼ì—ì„œ ë²„ìŠ¤ ë…¸ì„  ë¶ˆëŸ¬ì˜¤ê¸° (íŒŒì‹± ë¡œì§ í†µí•©)
# =======================
def load_bus_data():
    """
    CSV íŒŒì¼ì—ì„œ ë²„ìŠ¤ ë…¸ì„  ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    try:
        # íŒŒì¼ ê²½ë¡œëŠ” ì²¨ë¶€ëœ íŒŒì¼ì—ì„œ ì§€ì •ëœ ê²½ë¡œë¥¼ ë”°ë¦…ë‹ˆë‹¤.
        with open("/content/airport_bus_routes.csv", newline='', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            bus_data = [row for row in reader]
        
        # ë°ì´í„° íŒŒì‹±: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        list_cols = ['T1_weekday', 'T1_weekend', 'T2_weekday', 'T2_weekend', 'stops']
        
        parsed_data = []
        for row in bus_data:
            new_row = row.copy()
            for col in list_cols:
                if col in new_row and new_row[col]:
                    try:
                        # ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ í‰ê°€
                        new_row[col] = ast.literal_eval(new_row[col])
                    except:
                        new_row[col] = [] # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
            parsed_data.append(new_row)
            
        return parsed_data
    except Exception as e:
        print(f"Error loading and parsing bus data: {e}")
        return []

# =======================
# ğŸ§  ì„ë² ë”© ì²˜ë¦¬ (ë²„ìŠ¤ ì •ë³´) - Passage Generation Logic Integrated
# =======================
def create_bus_embeddings():
    """
    ë²„ìŠ¤ ë…¸ì„  ì •ë³´ë¥¼ ì„ë² ë”©í•˜ì—¬ ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤.
    (ì´ì „ì— ì„±ê³µí–ˆë˜ descriptive document structureë¥¼ ë”°ë¥´ë©° E5 prefixë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤)
    """
    bus_data = load_bus_data()
    documents = []
    metadatas = []
    ids = []

    for idx, row in enumerate(bus_data):
        
        # 1. Descriptive Passage Generation (ì´ì „ì— ì„±ê³µí•œ ê¸´ ë¬¸ì¥ êµ¬ì¡°)
        region = row.get("region", "")
        bus_no = row.get("bus_no", "")
        route_id = row.get("route_id", "")
        
        # load_bus_dataë¥¼ í†µí•´ ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±ëœ ë°ì´í„° ì‚¬ìš©
        stops = row.get("stops", []) 
        T1_weekday = row.get("T1_weekday", [])
        
        stops_str = ", ".join(stops) if stops else "ì •ë³´ ì—†ìŒ"
        t1_times = ", ".join(T1_weekday[:5]) # ì‹œê°„í‘œëŠ” ì• 5ê°œë§Œ ê°„ëµí•˜ê²Œ í¬í•¨
        
        doc_text = (
            # E5 ëª¨ë¸ ì ‘ë‘ì‚¬ 'passage:' ì¶”ê°€
            f"passage: {region} ì§€ì—­ ê³µí•­ë²„ìŠ¤ {bus_no}ë²ˆ ë…¸ì„  ì •ë³´ì…ë‹ˆë‹¤. "
            f"ë…¸ì„  IDëŠ” {route_id}ì…ë‹ˆë‹¤. "
            f"ì£¼ìš” ê²½ìœ  ì •ë¥˜ì¥ì€ {stops_str} ì…ë‹ˆë‹¤. "
            f"ì¸ì²œê³µí•­ ì œ1í„°ë¯¸ë„ í‰ì¼ ì²«ì°¨ ì‹œê°„ëŒ€ëŠ” {t1_times} ë“± ì…ë‹ˆë‹¤. "
            f"ì œ1í„°ë¯¸ë„ íƒ‘ìŠ¹ ìœ„ì¹˜ëŠ” {row.get('boarding_T1', 'ì •ë³´ ì—†ìŒ')}, "
            f"ì œ2í„°ë¯¸ë„ íƒ‘ìŠ¹ ìœ„ì¹˜ëŠ” {row.get('boarding_T2', 'ì •ë³´ ì—†ìŒ')} ì…ë‹ˆë‹¤."
        )
        documents.append(doc_text)
        
        # 2. Metadata Preparation (ChromaDB í˜¸í™˜: ë¦¬ìŠ¤íŠ¸ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜)
        metadata = row.copy()
        list_cols = ['T1_weekday', 'T1_weekend', 'T2_weekday', 'T2_weekend', 'stops']
        
        for col in list_cols:
            if col in metadata and isinstance(metadata[col], list):
                # ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì´í”„(|)ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                metadata[col] = "|".join(metadata[col]) 
            elif col in metadata and (pd.isna(metadata[col]) or metadata[col] is None):
                metadata[col] = "" # None/NaN ì²˜ë¦¬
        
        metadatas.append(metadata)
        
        # 3. ID Generation (ì´ì „ì— ì‚¬ìš©ëœ ê²°í•© í˜•ì‹ ì‚¬ìš©)
        ids.append(f"{region}_{bus_no}_{idx}") 

    # E5 ëª¨ë¸ì€ ì ‘ë‘ì‚¬ê°€ ì´ë¯¸ doc_textì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    embeddings = model.encode(documents, normalize_embeddings=True)

    collection.upsert(
        ids=ids,
        documents=documents,
        metadatas=metadatas,
        embeddings=embeddings
    )
    print(f"ì´ {len(documents)}ê°œì˜ ë²„ìŠ¤ ë…¸ì„  ì„ë² ë”© ì €ì¥ ì™„ë£Œ (Descriptive Text & E5 prefix).")


# =======================
# ğŸ§­ ChromaDB ê²€ìƒ‰ (ëª©ì ì§€ ê¸°ë°˜) - Faulty Metadata Filter ì œê±°
# =======================
def search_bus_routes(query: str, k=5):
    """
    LLMì„ í†µí•´ ëª©ì ì§€ë¥¼ ì¶”ì¶œí•˜ê³ , ChromaDBì—ì„œ í•´ë‹¹ ëª©ì ì§€ë¡œ ê°€ëŠ” ë²„ìŠ¤ ë…¸ì„  ê²€ìƒ‰
    (Metadata í•„í„° ëŒ€ì‹  Semantic Searchì— ì „ì ìœ¼ë¡œ ì˜ì¡´í•©ë‹ˆë‹¤.)
    """
    destination = extract_destination_from_query(query)
    print(f"ëª©ì ì§€ ì¶”ì¶œë¨: {destination}")

    # ì¶”ì¶œëœ ëª©ì ì§€ë¥¼ ì¿¼ë¦¬ì— í¬í•¨í•˜ê³ , E5 ëª¨ë¸ì˜ 'query:' ì ‘ë‘ì‚¬ë¥¼ ì‚¬ìš©
    query_text = f"query: {query} {destination}" if destination else f"query: {query}"

    query_embedding = model.encode([query_text], normalize_embeddings=True)
    res = collection.query(
        query_embeddings=query_embedding,
        # where=where_clause, # ë©”íƒ€ë°ì´í„° í•„í„° ë¯¸ì‚¬ìš©
        n_results=k
    )

    # ê²€ìƒ‰ëœ ê²°ê³¼ ì²˜ë¦¬
    docs = res["documents"][0]
    metas = res["metadatas"][0]
    dists = res["distances"][0]

    hits = []
    for doc, meta, dist in zip(docs, metas, dists):
        score = 1 - dist
        hits.append({"score": round(score, 4), "text": doc, "meta": meta})

    return hits


# =======================
# ğŸ“ LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (ìˆ˜ì •ëœ ë©”íƒ€ë°ì´í„° êµ¬ì¡° ë°˜ì˜)
# =======================
def build_bus_prompt(query: str, hits: list):
    """
    LLM í”„ë¡¬í”„íŠ¸ ìƒì„±: ê²€ìƒ‰ëœ ë²„ìŠ¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ
    """
    if not hits:
        return f"'{query}'ì— í•´ë‹¹í•˜ëŠ” ë²„ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    cards = []
    for h in hits[:5]:
        meta = h["meta"]
        bus_no = meta.get("bus_no", "-")
        # ë©”íƒ€ë°ì´í„°ì˜ stopsëŠ” ì´ì œ "|"ë¡œ joinëœ ë¬¸ìì—´ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        stops_str = meta.get("stops", "-") 
        T1_weekday = meta.get("T1_weekday", "-")
        T1_weekend = meta.get("T1_weekend", "-")
        T2_weekday = meta.get("T2_weekday", "-")
        T2_weekend = meta.get("T2_weekend", "-")
        
        cards.append(
            f"- ë²„ìŠ¤ {bus_no}ë²ˆ | ì •ë¥˜ì¥: {stops_str} | T1 í‰ì¼: {T1_weekday} | T1 ì£¼ë§: {T1_weekend} | T2 í‰ì¼: {T2_weekday} | T2 ì£¼ë§: {T2_weekend}"
        )

    ctx = "\n".join(cards)
    prompt = f"""
    ë‹¹ì‹ ì€ ì¸ì²œêµ­ì œê³µí•­ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤. 
    ì•„ë˜ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  í™œê¸°ì°¨ê²Œ ë‹µë³€í•˜ì„¸ìš”.
    - ì—¬ëŸ¬ ë…¸ì„ ì´ ìˆì„ ê²½ìš° ìš”ì•½í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
    - ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”. ëª¨ë¥´ëŠ” ì •ë³´ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
    - ë‹µë³€ì€ ë°˜ë“œì‹œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì¶©ì‹¤í•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”.

    ì‚¬ìš©ì ì§ˆë¬¸: "{query}"

    [ê²€ìƒ‰ëœ ë²„ìŠ¤ ì •ë³´]
    {ctx}
    """
    return prompt


# =======================
# ğŸ¢ ë²„ìŠ¤ ê²€ìƒ‰ ì²˜ë¦¬ (ë¼ìš°í„° ìœ ì§€)
# =======================
def search_bus_chroma(query: str, k=5):
    """
    ë²„ìŠ¤ ê²€ìƒ‰ ë° LLM ì‘ë‹µ ì²˜ë¦¬
    """
    hits = search_bus_routes(query, k=k)

    if not hits:
        return {"mode": "bus", "text": "í•´ë‹¹ ì¡°ê±´ì˜ ê³µí•­ë²„ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    prompt = build_bus_prompt(query, hits)
    answer = ask_llm(prompt)

    return {"mode": "bus", "text": answer}


def ask_llm(prompt: str) -> str:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±
    """
    response = openai_client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=300,
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

# NOTE: ì´ íŒŒì¼ì€ ëª¨ë“ˆë¡œ ì‘ë™í•˜ë¯€ë¡œ, __name__ == "__main__" ë¶€ë¶„ì€ ì œê±°í–ˆìŠµë‹ˆë‹¤.